{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from geopy.distance import geodesic \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# system setup\n",
    "user_info_filename = \"user_fix.csv\"\n",
    "trace_info_filename = \"traces_fix.csv\"\n",
    "\n",
    "# node config filename\n",
    "topology_filename = \"topology.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Preprocess User info data\n",
    "\n",
    "#### 1.1 load user\n",
    "load user and filter out users with no country info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load user info\n",
    "\n",
    "user_df = pd.read_csv(user_info_filename)\n",
    "trace_df = pd.read_csv(trace_info_filename)\n",
    "#print(user_df.columns)\n",
    "#print(trace_df.columns)\n",
    "\n",
    "# calculate the timestamp offset\n",
    "start_timestamp = trace_df.loc[0, \"timestamp\"]\n",
    "\n",
    "def timestamp_offset(ts):\n",
    "    return ts - start_timestamp\n",
    "\n",
    "trace_df[\"timestamp_offset\"] = trace_df[\"timestamp\"].apply(timestamp_offset)\n",
    "\n",
    "user_df = pd.merge(user_df, trace_df, on='user_id', how='inner')\n",
    "#print(user_df)\n",
    "#print(trace_df)\n",
    "\n",
    "value_counts = trace_df['file_url'].value_counts().head(1000)\n",
    "value_counts = value_counts[1:]\n",
    "\n",
    "value_counts.plot(kind='bar')\n",
    "plt.title(\"rank 20\")\n",
    "plt.xlabel(\"object name\")\n",
    "plt.ylabel(\"get count\")\n",
    "plt.xticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df['log_followers'] =np.log10(user_df['n_followers'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import percentileofscore\n",
    "import numpy as np\n",
    "\n",
    "user_df['cumulative'] = user_df['log_followers'].rank(method='min', ascending=True) / len(user_df)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=user_df, x='log_followers', y='cumulative')\n",
    "plt.title('Cumulative Frequency of n_followers')\n",
    "plt.xlabel('n_followers')\n",
    "plt.ylabel('Cumulative Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_df['level'] = pd.qcut(user_df['log_followers'], q=5, labels=[i+1 for i in range(5)])\n",
    "#print(user_df.head())\n",
    "\n",
    "#print(trace_df.head(10))\n",
    "trace_df[\"owner_id\"] = trace_df[\"file_url\"].str.split('-').str[0].astype(int)\n",
    "print(trace_df.head(100))\n",
    "\n",
    "trace_df = trace_df.merge(user_df[['user_id', 'level']], left_on='owner_id', right_on='user_id', how='left')\n",
    "print(trace_df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trace_df['level'].value_counts())\n",
    "\n",
    "trace_df = trace_df.drop(['user_id_y', 'owner_id'], axis=1)\n",
    "\n",
    "print(trace_df.head(100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 split user to different node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topology_json = \"\"\n",
    "with open(topology_filename) as json_file:\n",
    "    topology_json = json.load(json_file)\n",
    "\n",
    "access_nodes = topology_json[\"topology\"][\"layer-2\"]\n",
    "print(access_nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 allocate user to node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def euclidean_distance(lat1, lon1, lat2, lon2):\n",
    "    x = lat2 - lat1\n",
    "    y = lon2 - lon1\n",
    "    distance = math.sqrt(x**2 + y**2)\n",
    "\n",
    "    return distance\n",
    "\n",
    "def calculate_distance(row, nodes, prog_bar):\n",
    "    min_distance = 1000000000000000000\n",
    "    min_idx = -1\n",
    "    for idx, node in enumerate(nodes):\n",
    "        user_coords = (row['lat'], row['lng'])\n",
    "        node_coords = node[\"location\"]\n",
    "        distance = euclidean_distance(user_coords[0], -user_coords[1], node_coords[0], node_coords[1])\n",
    "        if min_idx == -1 :\n",
    "            min_idx = idx\n",
    "            min_distance = distance\n",
    "        elif distance < min_distance:\n",
    "            min_distance = distance\n",
    "            min_idx = idx\n",
    "\n",
    "    nodes[min_idx][\"users_id\"].append(row[\"user_id\"])\n",
    "    prog_bar.update(1)\n",
    "\n",
    "progress_bar = tqdm(user_df.iterrows(), total=len(user_df))\n",
    "\n",
    "for node in access_nodes: \n",
    "    node[\"users_id\"] = []\n",
    "\n",
    "user_df['distances'] = user_df.apply(calculate_distance, axis=1, nodes=access_nodes, prog_bar=progress_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in access_nodes:\n",
    "    print(len(node[\"users_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Extract node trace\n",
    "\n",
    "#### 2.1 allocate trace to node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_split_result = {}\n",
    "\n",
    "for node in access_nodes:\n",
    "    node_name = node[\"name\"]\n",
    "    users_id = node[\"users_id\"]\n",
    "    \n",
    "    mask = trace_df[\"user_id_x\"].isin(users_id)\n",
    "    \n",
    "    filtered_trace_df = trace_df[mask].reset_index(drop=True)\n",
    "    \n",
    "    # save result\n",
    "    trace_split_result[node_name] = filtered_trace_df\n",
    "\n",
    "for name, trace in trace_split_result.items():\n",
    "    print(name)\n",
    "    print(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 split to each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing aisa node\n",
    "# maximum trace line 10000\n",
    "# maximum container number 10\n",
    "max_line = 10000\n",
    "max_container = 20\n",
    "\n",
    "for node_name, node_traces in trace_split_result.items():\n",
    "    # asia-node\n",
    "    traces_size = len(node_traces)\n",
    "    print(node_name, \" with trace size \", traces_size)\n",
    "    container_num = traces_size // max_line\n",
    "    if container_num <= 0:\n",
    "        container_num = 1\n",
    "    elif container_num > 20:\n",
    "        container_num = 20\n",
    "\n",
    "    print(node_name, \" with container number \", container_num)\n",
    "    # split traces\n",
    "    split_dfs = [node_traces.iloc[i::container_num] for i in range(container_num)]\n",
    "    output_dir = \"./dataset/\" + node_name\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for idx, df in enumerate(split_dfs):\n",
    "        output_filename = output_dir + \"/\" + \"trace-%d\" %idx\n",
    "        df.to_csv(output_filename, header=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c00f29f07eec0d4f3978c4c7f9ebbe3f0d0563653e13954076c0f1f69cbf36d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

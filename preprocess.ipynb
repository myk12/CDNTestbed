{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from geopy.distance import geodesic \n",
    "\n",
    "# system setup\n",
    "user_info_filename = \"user_fix.csv\"\n",
    "trace_info_filename = \"traces_fix.csv\"\n",
    "\n",
    "# node config filename\n",
    "topology_filename = \"topology.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Preprocess User info data\n",
    "\n",
    "#### 1.1 load user\n",
    "load user and filter out users with no country info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load user info\n",
    "\n",
    "user_df = pd.read_csv(user_info_filename)\n",
    "trace_df = pd.read_csv(trace_info_filename)\n",
    "print(user_df.columns)\n",
    "print(trace_df.columns)\n",
    "\n",
    "user_df = pd.merge(user_df, trace_df, on='user_id', how='inner')\n",
    "print(len(user_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 split user to different node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topology_json = \"\"\n",
    "with open(topology_filename) as json_file:\n",
    "    topology_json = json.load(json_file)\n",
    "\n",
    "access_nodes = topology_json[\"topology\"][\"layer-2\"]\n",
    "print(access_nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 allocate user to node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(row, nodes, prog_bar):\n",
    "    min_distance = 1000000000000000000\n",
    "    min_idx = 0\n",
    "    for idx, node in enumerate(nodes):\n",
    "        user_coords = (row['lat'], row['lng'])\n",
    "        node_coords = node[\"location\"]\n",
    "        distance = geodesic(user_coords, node_coords)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            min_idx = idx\n",
    "    \n",
    "    nodes[min_idx][\"users_id\"].append(row[\"user_id\"])\n",
    "    prog_bar.update(1)\n",
    "\n",
    "progress_bar = tqdm(user_df.iterrows(), total=len(user_df))\n",
    "\n",
    "for node in access_nodes: \n",
    "    node[\"users_id\"] = []\n",
    "\n",
    "user_df['distances'] = user_df.apply(calculate_distance, axis=1, nodes=access_nodes, prog_bar=progress_bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Extract node trace\n",
    "\n",
    "#### 2.1 allocate trace to node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_split_result = {}\n",
    "\n",
    "for node in access_nodes:\n",
    "    node_name = node[\"name\"]\n",
    "    users_id = node[\"users_id\"]\n",
    "    \n",
    "    mask = trace_df[\"user_id\"].isin(users_id)\n",
    "    \n",
    "    filtered_trace_df = trace_df[mask].reset_index()\n",
    "    \n",
    "    # save result\n",
    "    trace_split_result[node_name] = filtered_trace_df\n",
    "\n",
    "for name, trace in trace_split_result.items():\n",
    "    print(name)\n",
    "    print(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 split to each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing aisa node\n",
    "# maximum trace line 10000\n",
    "# maximum container number 10\n",
    "max_line = 10000\n",
    "max_container = 20\n",
    "\n",
    "for node_name, node_traces in trace_split_result.items():\n",
    "    # asia-node\n",
    "    traces_size = len(node_traces)\n",
    "    print(node_name, \" with trace size \", traces_size)\n",
    "    container_num = traces_size // max_line\n",
    "    if container_num <= 0:\n",
    "        container_num = 1\n",
    "    elif container_num > 20:\n",
    "        container_num = 20\n",
    "\n",
    "    print(node_name, \" with container number \", container_num)\n",
    "    # split traces\n",
    "    split_dfs = [node_traces.iloc[i::container_num] for i in range(container_num)]\n",
    "    output_dir = \"./dataset/\" + node_name\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for idx, df in enumerate(split_dfs):\n",
    "        output_filename = output_dir + \"/\" + \"trace-%d\" %idx\n",
    "        df.to_csv(output_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c00f29f07eec0d4f3978c4c7f9ebbe3f0d0563653e13954076c0f1f69cbf36d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

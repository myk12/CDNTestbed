{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from geopy.distance import geodesic \n",
    "\n",
    "# system setup\n",
    "user_info_filename = \"user_fix.csv\"\n",
    "trace_info_filename = \"traces_fix.csv\"\n",
    "\n",
    "# node config filename\n",
    "topology_filename = \"topology.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Preprocess User info data\n",
    "\n",
    "#### 1.1 load user\n",
    "load user and filter out users with no country info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user_id  n_pin  n_followers  n_following  n_like_x  \\\n",
      "0             82   2497          441           99       262   \n",
      "1            420   3102           87           42       175   \n",
      "2           1515   1726           44          105      1303   \n",
      "3           1529   7884          302          177       966   \n",
      "4           1550   8264          281          135       894   \n",
      "...          ...    ...          ...          ...       ...   \n",
      "1193754  3022154   8035          558          313      1534   \n",
      "1193755  3022155    847           36          143        10   \n",
      "1193756  3022156   3471          227           57        11   \n",
      "1193757  3022158    574          299          285      1661   \n",
      "1193758  3022165   1068          575           94       106   \n",
      "\n",
      "         n_following_twitter  n_follower_twitter  n_tweet        lat  \\\n",
      "0                      238.0              8382.0   2140.0  29.760803   \n",
      "1                     1586.0               761.0   2558.0  35.582684   \n",
      "2                      136.0                35.0     83.0  33.195906   \n",
      "3                     1675.0              1097.0   3360.0  40.525526   \n",
      "4                      378.0                81.0   2212.0  39.323725   \n",
      "...                      ...                 ...      ...        ...   \n",
      "1193754                 -1.0                -1.0     -1.0  28.508333   \n",
      "1193755                 -1.0                -1.0     -1.0  36.705000   \n",
      "1193756                397.0               405.0   6767.0  36.705000   \n",
      "1193757                 -1.0                -1.0     -1.0  36.705000   \n",
      "1193758                 -1.0                -1.0     -1.0  44.901667   \n",
      "\n",
      "                lng  region   timestamp method            file_url  file_size  \\\n",
      "0        -95.369506       1  1370675737    GET      4135-49328.dat     167396   \n",
      "1        -97.508599       4  1370650715    GET    890917-46941.dat      64154   \n",
      "2       -117.379517       3  1370587888    GET  2439057-143777.dat      44780   \n",
      "3        -79.840601       5  1370844833    GET   2255041-78620.dat      12949   \n",
      "4       -111.678248       3  1371022821    GET  2373544-246694.dat      96893   \n",
      "...             ...     ...         ...    ...                 ...        ...   \n",
      "1193754  -76.608333       2  1371386010    GET    975464-29711.dat     155459   \n",
      "1193755  -95.885000       4  1371370515    GET    474706-38510.dat      83622   \n",
      "1193756  -76.608333       5  1371113803    GET     47123-42465.dat      35287   \n",
      "1193757  -76.608333       5  1370665570    GET  2636850-259578.dat      55318   \n",
      "1193758  -76.608333       8  1371842659   POST  3022165-167334.dat      52004   \n",
      "\n",
      "         n_like_y  timestamp_offset  \n",
      "0               0            141332  \n",
      "1               0            116310  \n",
      "2               0             53483  \n",
      "3               0            310428  \n",
      "4               0            488416  \n",
      "...           ...               ...  \n",
      "1193754         0            851605  \n",
      "1193755         0            836110  \n",
      "1193756         0            579398  \n",
      "1193757         0            131165  \n",
      "1193758         0           1308254  \n",
      "\n",
      "[1193759 rows x 17 columns]\n",
      "         user_id   timestamp method             file_url  file_size  n_like  \\\n",
      "0        2993811  1370534405   POST    2993811-27932.dat      35111       0   \n",
      "1        2308187  1370534417   POST    2308187-21838.dat      26447       0   \n",
      "2         172946  1370534418   POST     172946-21841.dat      42245       2   \n",
      "3        2039079  1370534418   POST     2039079-4720.dat      35763       0   \n",
      "4        1399414  1370534423   POST     1399414-1645.dat     173362       0   \n",
      "...          ...         ...    ...                  ...        ...     ...   \n",
      "1193754   113082  1374074924    GET    1660106-90931.dat      57386       0   \n",
      "1193755  2324093  1374076605    GET   1239822-377779.dat      34419       0   \n",
      "1193756  2806178  1374076607    GET  1733287-1640109.dat      21618       1   \n",
      "1193757  2653174  1374076613    GET   2814889-122868.dat      23635       0   \n",
      "1193758   958643  1374076614    GET   2507688-129998.dat      16721       1   \n",
      "\n",
      "         timestamp_offset  \n",
      "0                       0  \n",
      "1                      12  \n",
      "2                      13  \n",
      "3                      13  \n",
      "4                      18  \n",
      "...                   ...  \n",
      "1193754           3540519  \n",
      "1193755           3542200  \n",
      "1193756           3542202  \n",
      "1193757           3542208  \n",
      "1193758           3542209  \n",
      "\n",
      "[1193759 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# load user info\n",
    "\n",
    "user_df = pd.read_csv(user_info_filename)\n",
    "trace_df = pd.read_csv(trace_info_filename)\n",
    "#print(user_df.columns)\n",
    "#print(trace_df.columns)\n",
    "\n",
    "# calculate the timestamp offset\n",
    "start_timestamp = trace_df.loc[0, \"timestamp\"]\n",
    "\n",
    "def timestamp_offset(ts):\n",
    "    return ts - start_timestamp\n",
    "\n",
    "trace_df[\"timestamp_offset\"] = trace_df[\"timestamp\"].apply(timestamp_offset)\n",
    "\n",
    "user_df = pd.merge(user_df, trace_df, on='user_id', how='inner')\n",
    "print(user_df)\n",
    "print(trace_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 split user to different node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'access-0', 'name': 'Seattle', 'location': [47.6062, 122.3321], 'domain_name': '', 'ip_address': ''}, {'id': 'access-1', 'name': 'Los Angeles', 'location': [34.0522, 118.2437], 'domain_name': '', 'ip_address': ''}, {'id': 'access-2', 'name': 'New York', 'location': [40.7128, 74.006], 'domain_name': '', 'ip_address': ''}, {'id': 'access-3', 'name': 'Atlanta', 'location': [33.7438, 84.387], 'domain_name': '', 'ip_address': ''}]\n"
     ]
    }
   ],
   "source": [
    "topology_json = \"\"\n",
    "with open(topology_filename) as json_file:\n",
    "    topology_json = json.load(json_file)\n",
    "\n",
    "access_nodes = topology_json[\"topology\"][\"layer-2\"]\n",
    "print(access_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_df = user_df.head(20)\n",
    "#print(user_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 allocate user to node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1193759/1193759 [11:22<00:00, 1750.30it/s] \n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def euclidean_distance(lat1, lon1, lat2, lon2):\n",
    "    x = lat2 - lat1\n",
    "    y = lon2 - lon1\n",
    "    distance = math.sqrt(x**2 + y**2)\n",
    "\n",
    "    return distance\n",
    "\n",
    "def calculate_distance(row, nodes, prog_bar):\n",
    "    min_distance = 1000000000000000000\n",
    "    min_idx = -1\n",
    "    for idx, node in enumerate(nodes):\n",
    "        user_coords = (row['lat'], row['lng'])\n",
    "        node_coords = node[\"location\"]\n",
    "        distance = euclidean_distance(user_coords[0], -user_coords[1], node_coords[0], node_coords[1])\n",
    "        if min_idx == -1 :\n",
    "            min_idx = idx\n",
    "            min_distance = distance\n",
    "        elif distance < min_distance:\n",
    "            min_distance = distance\n",
    "            min_idx = idx\n",
    "\n",
    "    nodes[min_idx][\"users_id\"].append(row[\"user_id\"])\n",
    "    prog_bar.update(1)\n",
    "\n",
    "progress_bar = tqdm(user_df.iterrows(), total=len(user_df))\n",
    "\n",
    "for node in access_nodes: \n",
    "    node[\"users_id\"] = []\n",
    "\n",
    "user_df['distances'] = user_df.apply(calculate_distance, axis=1, nodes=access_nodes, prog_bar=progress_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57289\n",
      "198480\n",
      "488961\n",
      "449029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for node in access_nodes:\n",
    "    print(len(node[\"users_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Extract node trace\n",
    "\n",
    "#### 2.1 allocate trace to node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seattle\n",
      "       user_id   timestamp method             file_url  file_size  n_like  \\\n",
      "0       277045  1370534496   POST     277045-69529.dat      26094       0   \n",
      "1       364458  1370534499   POST     364458-69559.dat      27548       0   \n",
      "2      2923017  1370534500    GET     239353-69563.dat      38575       0   \n",
      "3       638653  1370534501    GET     378601-69576.dat     105661       0   \n",
      "4      1092132  1370534511    GET     333785-69874.dat      29956       0   \n",
      "...        ...         ...    ...                  ...        ...     ...   \n",
      "57284  1219440  1374015962    GET   1929204-136827.dat      11377       2   \n",
      "57285  1277511  1374030786    GET    1557893-91215.dat      33623       0   \n",
      "57286   564725  1374032726    GET    2836425-76214.dat      57048       0   \n",
      "57287  2500963  1374034522    GET  2874298-1114398.dat      66752       0   \n",
      "57288  2725703  1374060488    GET    2866554-79480.dat      48526       0   \n",
      "\n",
      "       timestamp_offset  \n",
      "0                    91  \n",
      "1                    94  \n",
      "2                    95  \n",
      "3                    96  \n",
      "4                   106  \n",
      "...                 ...  \n",
      "57284           3481557  \n",
      "57285           3496381  \n",
      "57286           3498321  \n",
      "57287           3500117  \n",
      "57288           3526083  \n",
      "\n",
      "[57289 rows x 7 columns]\n",
      "Los Angeles\n",
      "        user_id   timestamp method            file_url  file_size  n_like  \\\n",
      "0       1399414  1370534423   POST    1399414-1645.dat     173362       0   \n",
      "1       2671645  1370534431   POST    2671645-4771.dat      40677       0   \n",
      "2       1786789  1370534481   POST   1786789-23881.dat      37448       0   \n",
      "3       1525289  1370534488    GET    502495-69444.dat      40328       1   \n",
      "4        672583  1370534488   POST    672583-69443.dat      21972       0   \n",
      "...         ...         ...    ...                 ...        ...     ...   \n",
      "198475  2385251  1374040961    GET   1665590-91273.dat      31779       0   \n",
      "198476  1701284  1374040971    GET   2412433-91103.dat     144368       0   \n",
      "198477  2630874  1374049752    GET    930118-90428.dat      74988       0   \n",
      "198478   505727  1374065799    GET  2643015-112633.dat      10008       3   \n",
      "198479  2653174  1374076613    GET  2814889-122868.dat      23635       0   \n",
      "\n",
      "        timestamp_offset  \n",
      "0                     18  \n",
      "1                     26  \n",
      "2                     76  \n",
      "3                     83  \n",
      "4                     83  \n",
      "...                  ...  \n",
      "198475           3506556  \n",
      "198476           3506566  \n",
      "198477           3515347  \n",
      "198478           3531394  \n",
      "198479           3542208  \n",
      "\n",
      "[198480 rows x 7 columns]\n",
      "New York\n",
      "        user_id   timestamp method             file_url  file_size  n_like  \\\n",
      "0        172946  1370534418   POST     172946-21841.dat      42245       2   \n",
      "1       2039079  1370534418   POST     2039079-4720.dat      35763       0   \n",
      "2        924774  1370534470   POST     924774-68885.dat      66527       1   \n",
      "3       2524293  1370534472   POST    2524293-28372.dat     128331       0   \n",
      "4        346380  1370534475   POST     346380-68962.dat      95635       4   \n",
      "...         ...         ...    ...                  ...        ...     ...   \n",
      "488956  2667060  1374069395    GET   2006187-221050.dat       6862       0   \n",
      "488957  1605043  1374072411    GET    2943931-73501.dat      52469       0   \n",
      "488958   113082  1374074924    GET    1660106-90931.dat      57386       0   \n",
      "488959  2806178  1374076607    GET  1733287-1640109.dat      21618       1   \n",
      "488960   958643  1374076614    GET   2507688-129998.dat      16721       1   \n",
      "\n",
      "        timestamp_offset  \n",
      "0                     13  \n",
      "1                     13  \n",
      "2                     65  \n",
      "3                     67  \n",
      "4                     70  \n",
      "...                  ...  \n",
      "488956           3534990  \n",
      "488957           3538006  \n",
      "488958           3540519  \n",
      "488959           3542202  \n",
      "488960           3542209  \n",
      "\n",
      "[488961 rows x 7 columns]\n",
      "Atlanta\n",
      "        user_id   timestamp method            file_url  file_size  n_like  \\\n",
      "0       2993811  1370534405   POST   2993811-27932.dat      35111       0   \n",
      "1       2308187  1370534417   POST   2308187-21838.dat      26447       0   \n",
      "2        104377  1370534427   POST     104377-2100.dat     112988       1   \n",
      "3       1517294  1370534459   POST    1517294-3394.dat      17050       0   \n",
      "4       2107321  1370534474   POST    2107321-1532.dat      48215       1   \n",
      "...         ...         ...    ...                 ...        ...     ...   \n",
      "449024  2913899  1374058567    GET  2758104-118720.dat      42654       1   \n",
      "449025   160886  1374059037    GET    412495-58667.dat      37247       0   \n",
      "449026  1908400  1374062661    GET   2866554-79480.dat      48526       0   \n",
      "449027  1083092  1374062817    GET   344824-568871.dat      97005       2   \n",
      "449028  2324093  1374076605    GET  1239822-377779.dat      34419       0   \n",
      "\n",
      "        timestamp_offset  \n",
      "0                      0  \n",
      "1                     12  \n",
      "2                     22  \n",
      "3                     54  \n",
      "4                     69  \n",
      "...                  ...  \n",
      "449024           3524162  \n",
      "449025           3524632  \n",
      "449026           3528256  \n",
      "449027           3528412  \n",
      "449028           3542200  \n",
      "\n",
      "[449029 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "trace_split_result = {}\n",
    "\n",
    "for node in access_nodes:\n",
    "    node_name = node[\"name\"]\n",
    "    users_id = node[\"users_id\"]\n",
    "    \n",
    "    mask = trace_df[\"user_id\"].isin(users_id)\n",
    "    \n",
    "    filtered_trace_df = trace_df[mask].reset_index(drop=True)\n",
    "    \n",
    "    # save result\n",
    "    trace_split_result[node_name] = filtered_trace_df\n",
    "\n",
    "for name, trace in trace_split_result.items():\n",
    "    print(name)\n",
    "    print(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 split to each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seattle  with trace size  57289\n",
      "Seattle  with container number  5\n",
      "Los Angeles  with trace size  198480\n",
      "Los Angeles  with container number  19\n",
      "New York  with trace size  488961\n",
      "New York  with container number  20\n",
      "Atlanta  with trace size  449029\n",
      "Atlanta  with container number  20\n"
     ]
    }
   ],
   "source": [
    "# doing aisa node\n",
    "# maximum trace line 10000\n",
    "# maximum container number 10\n",
    "max_line = 10000\n",
    "max_container = 20\n",
    "\n",
    "for node_name, node_traces in trace_split_result.items():\n",
    "    # asia-node\n",
    "    traces_size = len(node_traces)\n",
    "    print(node_name, \" with trace size \", traces_size)\n",
    "    container_num = traces_size // max_line\n",
    "    if container_num <= 0:\n",
    "        container_num = 1\n",
    "    elif container_num > 20:\n",
    "        container_num = 20\n",
    "\n",
    "    print(node_name, \" with container number \", container_num)\n",
    "    # split traces\n",
    "    split_dfs = [node_traces.iloc[i::container_num] for i in range(container_num)]\n",
    "    output_dir = \"./dataset/\" + node_name\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for idx, df in enumerate(split_dfs):\n",
    "        output_filename = output_dir + \"/\" + \"trace-%d\" %idx\n",
    "        df.to_csv(output_filename, header=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c00f29f07eec0d4f3978c4c7f9ebbe3f0d0563653e13954076c0f1f69cbf36d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from geopy.distance import geodesic \n",
    "\n",
    "# system setup\n",
    "user_info_filename = \"user_fix.csv\"\n",
    "trace_info_filename = \"traces_fix.csv\"\n",
    "\n",
    "# node config filename\n",
    "topology_filename = \"topology.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Preprocess User info data\n",
    "\n",
    "#### 1.1 load user\n",
    "load user and filter out users with no country info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user_id   timestamp method             file_url  file_size  n_like  \\\n",
      "0        2993811  1370534405   POST    2993811-27932.dat      35111       0   \n",
      "1        2308187  1370534417   POST    2308187-21838.dat      26447       0   \n",
      "2         172946  1370534418   POST     172946-21841.dat      42245       2   \n",
      "3        2039079  1370534418   POST     2039079-4720.dat      35763       0   \n",
      "4        1399414  1370534423   POST     1399414-1645.dat     173362       0   \n",
      "...          ...         ...    ...                  ...        ...     ...   \n",
      "1193754   113082  1374074924    GET    1660106-90931.dat      57386       0   \n",
      "1193755  2324093  1374076605    GET   1239822-377779.dat      34419       0   \n",
      "1193756  2806178  1374076607    GET  1733287-1640109.dat      21618       1   \n",
      "1193757  2653174  1374076613    GET   2814889-122868.dat      23635       0   \n",
      "1193758   958643  1374076614    GET   2507688-129998.dat      16721       1   \n",
      "\n",
      "         timestamp_offset  \n",
      "0                       0  \n",
      "1                      12  \n",
      "2                      13  \n",
      "3                      13  \n",
      "4                      18  \n",
      "...                   ...  \n",
      "1193754           3540519  \n",
      "1193755           3542200  \n",
      "1193756           3542202  \n",
      "1193757           3542208  \n",
      "1193758           3542209  \n",
      "\n",
      "[1193759 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# load user info\n",
    "\n",
    "user_df = pd.read_csv(user_info_filename)\n",
    "trace_df = pd.read_csv(trace_info_filename)\n",
    "#print(user_df.columns)\n",
    "#print(trace_df.columns)\n",
    "\n",
    "# calculate the timestamp offset\n",
    "start_timestamp = trace_df.loc[0, \"timestamp\"]\n",
    "\n",
    "def timestamp_offset(ts):\n",
    "    return ts - start_timestamp\n",
    "\n",
    "trace_df[\"timestamp_offset\"] = trace_df[\"timestamp\"].apply(timestamp_offset)\n",
    "\n",
    "user_df = pd.merge(user_df, trace_df, on='user_id', how='inner')\n",
    "#print(len(user_df))\n",
    "print(trace_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 split user to different node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'access-0', 'name': 'access-0', 'location': [40.76, 111.84], 'domain_name': '', 'IP_address': ''}, {'id': 'access-1', 'name': 'access-1', 'location': [43.07, 89.41], 'domain_name': ''}, {'id': 'access-2', 'name': 'access-2', 'location': [34.67, 82.84], 'domain_name': ''}]\n"
     ]
    }
   ],
   "source": [
    "topology_json = \"\"\n",
    "with open(topology_filename) as json_file:\n",
    "    topology_json = json.load(json_file)\n",
    "\n",
    "access_nodes = topology_json[\"topology\"][\"layer-2\"]\n",
    "print(access_nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 allocate user to node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1193636/1193759 [13:07<00:00, 1528.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1193759/1193759 [13:20<00:00, 1528.32it/s]"
     ]
    }
   ],
   "source": [
    "def calculate_distance(row, nodes, prog_bar):\n",
    "    min_distance = 1000000000000000000\n",
    "    min_idx = 0\n",
    "    for idx, node in enumerate(nodes):\n",
    "        user_coords = (row['lat'], row['lng'])\n",
    "        node_coords = node[\"location\"]\n",
    "        distance = geodesic(user_coords, node_coords)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            min_idx = idx\n",
    "    \n",
    "    nodes[min_idx][\"users_id\"].append(row[\"user_id\"])\n",
    "    prog_bar.update(1)\n",
    "\n",
    "progress_bar = tqdm(user_df.iterrows(), total=len(user_df))\n",
    "\n",
    "for node in access_nodes: \n",
    "    node[\"users_id\"] = []\n",
    "\n",
    "user_df['distances'] = user_df.apply(calculate_distance, axis=1, nodes=access_nodes, prog_bar=progress_bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Extract node trace\n",
    "\n",
    "#### 2.1 allocate trace to node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "access-0\n",
      "          index  user_id   timestamp method            file_url  file_size  \\\n",
      "0             0  2993811  1370534405   POST   2993811-27932.dat      35111   \n",
      "1             1  2308187  1370534417   POST   2308187-21838.dat      26447   \n",
      "2             4  1399414  1370534423   POST    1399414-1645.dat     173362   \n",
      "3             5   104377  1370534427   POST     104377-2100.dat     112988   \n",
      "4             6  2671645  1370534431   POST    2671645-4771.dat      40677   \n",
      "...         ...      ...         ...    ...                 ...        ...   \n",
      "633800  1193745  2725703  1374060488    GET   2866554-79480.dat      48526   \n",
      "633801  1193748  1908400  1374062661    GET   2866554-79480.dat      48526   \n",
      "633802  1193749  1083092  1374062817    GET   344824-568871.dat      97005   \n",
      "633803  1193751   505727  1374065799    GET  2643015-112633.dat      10008   \n",
      "633804  1193757  2653174  1374076613    GET  2814889-122868.dat      23635   \n",
      "\n",
      "        n_like  timestamp_offset  \n",
      "0            0                 0  \n",
      "1            0                12  \n",
      "2            0                18  \n",
      "3            1                22  \n",
      "4            0                26  \n",
      "...        ...               ...  \n",
      "633800       0           3526083  \n",
      "633801       0           3528256  \n",
      "633802       2           3528412  \n",
      "633803       3           3531394  \n",
      "633804       0           3542208  \n",
      "\n",
      "[633805 rows x 8 columns]\n",
      "access-1\n",
      "          index  user_id   timestamp method             file_url  file_size  \\\n",
      "0             2   172946  1370534418   POST     172946-21841.dat      42245   \n",
      "1             3  2039079  1370534418   POST     2039079-4720.dat      35763   \n",
      "2             8   924774  1370534470   POST     924774-68885.dat      66527   \n",
      "3             9  2524293  1370534472   POST    2524293-28372.dat     128331   \n",
      "4            12   346380  1370534475   POST     346380-68962.dat      95635   \n",
      "...         ...      ...         ...    ...                  ...        ...   \n",
      "559949  1193753  1605043  1374072411    GET    2943931-73501.dat      52469   \n",
      "559950  1193754   113082  1374074924    GET    1660106-90931.dat      57386   \n",
      "559951  1193755  2324093  1374076605    GET   1239822-377779.dat      34419   \n",
      "559952  1193756  2806178  1374076607    GET  1733287-1640109.dat      21618   \n",
      "559953  1193758   958643  1374076614    GET   2507688-129998.dat      16721   \n",
      "\n",
      "        n_like  timestamp_offset  \n",
      "0            2                13  \n",
      "1            0                13  \n",
      "2            1                65  \n",
      "3            0                67  \n",
      "4            4                70  \n",
      "...        ...               ...  \n",
      "559949       0           3538006  \n",
      "559950       0           3540519  \n",
      "559951       0           3542200  \n",
      "559952       1           3542202  \n",
      "559953       1           3542209  \n",
      "\n",
      "[559954 rows x 8 columns]\n",
      "access-2\n",
      "Empty DataFrame\n",
      "Columns: [index, user_id, timestamp, method, file_url, file_size, n_like, timestamp_offset]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "trace_split_result = {}\n",
    "\n",
    "for node in access_nodes:\n",
    "    node_name = node[\"name\"]\n",
    "    users_id = node[\"users_id\"]\n",
    "    \n",
    "    mask = trace_df[\"user_id\"].isin(users_id)\n",
    "    \n",
    "    filtered_trace_df = trace_df[mask].reset_index(drop=True)\n",
    "    \n",
    "    # save result\n",
    "    trace_split_result[node_name] = filtered_trace_df\n",
    "\n",
    "for name, trace in trace_split_result.items():\n",
    "    print(name)\n",
    "    print(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 split to each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "access-0  with trace size  633805\n",
      "access-0  with container number  20\n",
      "access-1  with trace size  559954\n",
      "access-1  with container number  20\n",
      "access-2  with trace size  0\n",
      "access-2  with container number  1\n"
     ]
    }
   ],
   "source": [
    "# doing aisa node\n",
    "# maximum trace line 10000\n",
    "# maximum container number 10\n",
    "max_line = 10000\n",
    "max_container = 20\n",
    "\n",
    "for node_name, node_traces in trace_split_result.items():\n",
    "    # asia-node\n",
    "    traces_size = len(node_traces)\n",
    "    print(node_name, \" with trace size \", traces_size)\n",
    "    container_num = traces_size // max_line\n",
    "    if container_num <= 0:\n",
    "        container_num = 1\n",
    "    elif container_num > 20:\n",
    "        container_num = 20\n",
    "\n",
    "    print(node_name, \" with container number \", container_num)\n",
    "    # split traces\n",
    "    split_dfs = [node_traces.iloc[i::container_num] for i in range(container_num)]\n",
    "    output_dir = \"./dataset/\" + node_name\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for idx, df in enumerate(split_dfs):\n",
    "        output_filename = output_dir + \"/\" + \"trace-%d\" %idx\n",
    "        df.to_csv(output_filename, header=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
